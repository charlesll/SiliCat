// Licensed under the Apache License, Version 2.0
// http://www.apache.org/licenses/LICENSE-2.0.html
//
// AUTOGENERATED BY H2O at 2015-09-04T12:45:20.711-04:00
// 3.0.0.25
//
// Standalone prediction code with sample test data for DeepLearningModel named deeplearning_1bfa7a81_7686_4690_a685_d441d7382510
//
// How to download, compile and execute:
//     mkdir tmpdir
//     cd tmpdir
//     curl http://10.1.15.176:54321/3/h2o-genmodel.jar > h2o-genmodel.jar
//     curl http://10.1.15.176:54321/3/Models.java/deeplearning-1bfa7a81-7686-4690-a685-d441d7382510 > deeplearning_1bfa7a81_7686_4690_a685_d441d7382510.java
//     javac -cp h2o-genmodel.jar -J-Xmx2g -J-XX:MaxPermSize=128m deeplearning_1bfa7a81_7686_4690_a685_d441d7382510.java
//
//     (Note:  Try java argument -XX:+PrintCompilation to show runtime JIT compiler behavior.)
import java.util.Map;
import hex.genmodel.GenModel;

public class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510 extends GenModel {
  public hex.ModelCategory getModelCategory() { return hex.ModelCategory.Regression; }
  public boolean isSupervised() { return true; }
  public int nfeatures() { return 15; }
  public int nclasses() { return 1; }
  // Workspace for storing numerical input variables.
  public static final double[] NUMS = {0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0};
  // Standardization/Normalization scaling factor for numerical variables.
  public static final double[] NORMMUL = {0.06535414467994424,0.43073536864064343,0.1146548783365077,0.12731102594866384,0.16560042860535093,0.3126108295206521,0.25557210453765283,0.09798814376570732,0.07357610997264465,0.24729676295237568,0.1117680309268793,0.2878171284388378,11.706478683571316,0.2912058113403427,0.0023327344035190332};
  // Standardization/Normalization offset for numerical variables.
  public static final double[] NORMSUB = {62.1217892824695,0.4113260672116251,10.348667120799218,1.9152179836512269,0.8265940054495908,0.29212079927338785,0.37336512261580374,5.043576294277926,8.820408719346005,0.4739441416893733,6.4973978201634655,1.6385649409627516,0.017284287011807453,1.2261625794732096,1353.500567665804};
  // Workspace for categorical offsets.
  public static final int[] CATOFFSETS = {0};
  // Standardization/Normalization scaling factor for response.
  public static final double[] NORMRESPMUL = {0.20589970602941074};
  // Standardization/Normalization offset for response.
  public static final double[] NORMRESPSUB = {6.191666439600349};
  // Number of neurons for each layer.
  public static final int[] NEURONS = {15,8,4,1};
    // Storage for neuron activation values.
    public static final float[][] ACTIVATION = new float[][] {
      /* Input */ deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Activation_0.VALUES,
      /* Rectifier */ deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Activation_1.VALUES,
      /* Rectifier */ deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Activation_2.VALUES,
      /* Linear */ deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Activation_3.VALUES
    };
    // Neuron bias values.
    public static final float[][] BIAS = new float[][] {
      /* Input */ deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Bias_0.VALUES,
      /* Rectifier */ deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Bias_1.VALUES,
      /* Rectifier */ deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Bias_2.VALUES,
      /* Linear */ deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Bias_3.VALUES
    };
    // Connecting weights between neurons.
    public static final float[][] WEIGHT = new float[][] {
      /* Input */ deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Weight_0.VALUES,
      /* Rectifier */ deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Weight_1.VALUES,
      /* Rectifier */ deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Weight_2.VALUES,
      /* Linear */ deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Weight_3.VALUES
    };

  // Names of columns used by model.
  public static final String[] NAMES = NamesHolder_deeplearning_1bfa7a81_7686_4690_a685_d441d7382510.VALUES;

  // Column domains. The last array contains domain of response column.
  public static final String[][] DOMAINS = new String[][] {
    /* SiO2 */ null,
    /* TiO2 */ null,
    /* Al2O3 */ null,
    /* FeOt */ null,
    /* MnO */ null,
    /* BaO */ null,
    /* SrO */ null,
    /* MgO */ null,
    /* CaO */ null,
    /* Li2O */ null,
    /* Na2O */ null,
    /* K2O */ null,
    /* P2O5 */ null,
    /* H2O */ null,
    /* T (K) */ null,
    /* Visco Pa s */ null
  };
  // Prior class distribution
  public static final double[] PRIOR_CLASS_DISTRIB = null;
  // Class distribution used for model building
  public static final double[] MODEL_CLASS_DISTRIB = null;

  public deeplearning_1bfa7a81_7686_4690_a685_d441d7382510() { super(NAMES,DOMAINS); }
  public String getUUID() { return Long.toString(5093661667451531488L); }

  // Pass in data in a double[], pre-aligned to the Model's requirements.
  // Jam predictions into the preds[] array; preds[0] is reserved for the
  // main prediction (class for classifiers or value for regression),
  // and remaining columns hold a probability distribution for classifiers.
  public final double[] score0( double[] data, double[] preds ) {
    java.util.Arrays.fill(preds,0);
    java.util.Arrays.fill(NUMS,0f);
    int i = 0, ncats = 0;
    final int n = data.length;
    for(; i<n; ++i) {
      NUMS[i] = Double.isNaN(data[i]) ? 0 : (data[i] - NORMSUB[i])*NORMMUL[i];
    }
    java.util.Arrays.fill(ACTIVATION[0],0);
    for (i=0; i<NUMS.length; ++i) {
      ACTIVATION[0][CATOFFSETS[CATOFFSETS.length-1] + i] = Double.isNaN(NUMS[i]) ? 0f : (float) NUMS[i];
    }
    for (i=1; i<ACTIVATION.length; ++i) {
      java.util.Arrays.fill(ACTIVATION[i],0f);
      int cols = ACTIVATION[i-1].length;
      int rows = ACTIVATION[i].length;
      int extra=cols-cols%8;
      int multiple = (cols/8)*8-1;
      int idx = 0;
      float[] a = WEIGHT[i];
      float[] x = ACTIVATION[i-1];
      float[] y = BIAS[i];
      float[] res = ACTIVATION[i];
      for (int row=0; row<rows; ++row) {
        float psum0 = 0, psum1 = 0, psum2 = 0, psum3 = 0, psum4 = 0, psum5 = 0, psum6 = 0, psum7 = 0;
        for (int col = 0; col < multiple; col += 8) {
          int off = idx + col;
          psum0 += a[off    ] * x[col    ];
          psum1 += a[off + 1] * x[col + 1];
          psum2 += a[off + 2] * x[col + 2];
          psum3 += a[off + 3] * x[col + 3];
          psum4 += a[off + 4] * x[col + 4];
          psum5 += a[off + 5] * x[col + 5];
          psum6 += a[off + 6] * x[col + 6];
          psum7 += a[off + 7] * x[col + 7];
        }
        res[row] += psum0 + psum1 + psum2 + psum3;
        res[row] += psum4 + psum5 + psum6 + psum7;
        for (int col = extra; col < cols; col++)
          res[row] += a[idx + col] * x[col];
        res[row] += y[row];
        idx += cols;
      }
      if (i<ACTIVATION.length-1) {
        for (int r=0; r<ACTIVATION[i].length; ++r) {
          ACTIVATION[i][r] = Math.max(0f, ACTIVATION[i][r]);
        }
      }
      if (i == ACTIVATION.length-1) {
        preds[1] = (ACTIVATION[i][0] / NORMRESPMUL[0] + NORMRESPSUB[0]);
        if (Double.isNaN(preds[1])) throw new RuntimeException("Predicted regression target NaN!");
      }
    }
    preds[0] = (float)preds[1];
    return preds;
  }
}
// Neuron activation values for Input layer
class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Activation_0 implements java.io.Serializable {
  public static final float[] VALUES = new float[15];
  static {
    deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Activation_0_0.fill(VALUES);
  }
  static final class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Activation_0_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = 0.0f;
      sa[1] = 0.0f;
      sa[2] = 0.0f;
      sa[3] = 0.0f;
      sa[4] = 0.0f;
      sa[5] = 0.0f;
      sa[6] = 0.0f;
      sa[7] = 0.0f;
      sa[8] = 0.0f;
      sa[9] = 0.0f;
      sa[10] = 0.0f;
      sa[11] = 0.0f;
      sa[12] = 0.0f;
      sa[13] = 0.0f;
      sa[14] = 0.0f;
    }
  }
}
// Neuron activation values for Rectifier layer
class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Activation_1 implements java.io.Serializable {
  public static final float[] VALUES = new float[8];
  static {
    deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Activation_1_0.fill(VALUES);
  }
  static final class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Activation_1_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = 0.0f;
      sa[1] = 0.0f;
      sa[2] = 0.0f;
      sa[3] = 0.0f;
      sa[4] = 0.0f;
      sa[5] = 0.0f;
      sa[6] = 0.0f;
      sa[7] = 0.0f;
    }
  }
}
// Neuron activation values for Rectifier layer
class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Activation_2 implements java.io.Serializable {
  public static final float[] VALUES = new float[4];
  static {
    deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Activation_2_0.fill(VALUES);
  }
  static final class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Activation_2_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = 0.0f;
      sa[1] = 0.0f;
      sa[2] = 0.0f;
      sa[3] = 0.0f;
    }
  }
}
// Neuron activation values for Linear layer
class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Activation_3 implements java.io.Serializable {
  public static final float[] VALUES = new float[1];
  static {
    deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Activation_3_0.fill(VALUES);
  }
  static final class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Activation_3_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = 0.0f;
    }
  }
}
// Neuron bias values for Input layer
class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Bias_0 implements java.io.Serializable {
  public static final float[] VALUES = null;
}
// Neuron bias values for Rectifier layer
class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Bias_1 implements java.io.Serializable {
  public static final float[] VALUES = new float[8];
  static {
    deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Bias_1_0.fill(VALUES);
  }
  static final class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Bias_1_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = -0.35357153f;
      sa[1] = 0.11113945f;
      sa[2] = 0.021818094f;
      sa[3] = -0.38949665f;
      sa[4] = -0.02406104f;
      sa[5] = 0.33781546f;
      sa[6] = -0.35623187f;
      sa[7] = 0.3086386f;
    }
  }
}
// Neuron bias values for Rectifier layer
class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Bias_2 implements java.io.Serializable {
  public static final float[] VALUES = new float[4];
  static {
    deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Bias_2_0.fill(VALUES);
  }
  static final class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Bias_2_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = 0.2124831f;
      sa[1] = -0.12791312f;
      sa[2] = -2.399645E-5f;
      sa[3] = 0.29989862f;
    }
  }
}
// Neuron bias values for Linear layer
class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Bias_3 implements java.io.Serializable {
  public static final float[] VALUES = new float[1];
  static {
    deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Bias_3_0.fill(VALUES);
  }
  static final class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Bias_3_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = -0.24820746f;
    }
  }
}
class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Weight_0 implements java.io.Serializable {
  public static final float[] VALUES = null;
}
// Neuron weights connecting Input and Rectifier layer
class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Weight_1 implements java.io.Serializable {
  public static final float[] VALUES = new float[120];
  static {
    deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Weight_1_0.fill(VALUES);
  }
  static final class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Weight_1_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = -0.24586834f;
      sa[1] = 0.1624283f;
      sa[2] = -0.079175994f;
      sa[3] = -0.009929085f;
      sa[4] = 0.10111241f;
      sa[5] = 0.07994278f;
      sa[6] = 0.09157663f;
      sa[7] = -0.24419674f;
      sa[8] = 0.008671295f;
      sa[9] = 0.06875378f;
      sa[10] = 0.18064326f;
      sa[11] = -0.10097007f;
      sa[12] = -0.01686638f;
      sa[13] = 0.05354804f;
      sa[14] = -0.25611147f;
      sa[15] = -0.08553053f;
      sa[16] = 0.06551462f;
      sa[17] = 0.17604722f;
      sa[18] = 0.060702875f;
      sa[19] = 0.0738766f;
      sa[20] = -0.0113292225f;
      sa[21] = 0.0158088f;
      sa[22] = 0.058153175f;
      sa[23] = 0.013004774f;
      sa[24] = 0.07785527f;
      sa[25] = -0.22049735f;
      sa[26] = -0.07699213f;
      sa[27] = 0.0035863237f;
      sa[28] = 0.039294615f;
      sa[29] = 0.07989108f;
      sa[30] = 0.094260015f;
      sa[31] = 0.0046963994f;
      sa[32] = 0.11063213f;
      sa[33] = -0.10878035f;
      sa[34] = -0.0012142425f;
      sa[35] = -0.0068589104f;
      sa[36] = -3.0547968E-4f;
      sa[37] = -0.23072831f;
      sa[38] = -0.0059831557f;
      sa[39] = -0.03786059f;
      sa[40] = -0.03137641f;
      sa[41] = -0.11028902f;
      sa[42] = -0.012768508f;
      sa[43] = -0.35448658f;
      sa[44] = -0.04129914f;
      sa[45] = 0.22528689f;
      sa[46] = 0.031681806f;
      sa[47] = -0.021611538f;
      sa[48] = 0.02321781f;
      sa[49] = 0.01994765f;
      sa[50] = -0.27702814f;
      sa[51] = -0.006011753f;
      sa[52] = 0.038986232f;
      sa[53] = 0.017396482f;
      sa[54] = -0.027955985f;
      sa[55] = -0.4042468f;
      sa[56] = -0.027055992f;
      sa[57] = 0.003649917f;
      sa[58] = 0.1929084f;
      sa[59] = -0.03478502f;
      sa[60] = 0.010484372f;
      sa[61] = -0.08364489f;
      sa[62] = 0.21573566f;
      sa[63] = -0.1675284f;
      sa[64] = -0.032255724f;
      sa[65] = -0.0027682595f;
      sa[66] = -0.0035244566f;
      sa[67] = -0.029590795f;
      sa[68] = -0.24777842f;
      sa[69] = -0.0902148f;
      sa[70] = -0.24602355f;
      sa[71] = -0.003383457f;
      sa[72] = -0.1192525f;
      sa[73] = -0.2862456f;
      sa[74] = -0.7394483f;
      sa[75] = -0.099476226f;
      sa[76] = -0.057473693f;
      sa[77] = -0.31108135f;
      sa[78] = 0.15098815f;
      sa[79] = 9.992732E-4f;
      sa[80] = 0.05983463f;
      sa[81] = 0.059136525f;
      sa[82] = -6.908007E-4f;
      sa[83] = 0.21310192f;
      sa[84] = 0.048325177f;
      sa[85] = 0.15930995f;
      sa[86] = 0.055516314f;
      sa[87] = -0.011579663f;
      sa[88] = 0.1088854f;
      sa[89] = -0.027618295f;
      sa[90] = -0.26783177f;
      sa[91] = 0.030104898f;
      sa[92] = -0.27393895f;
      sa[93] = 0.09568709f;
      sa[94] = 0.010493056f;
      sa[95] = 0.0043322695f;
      sa[96] = 0.0050667217f;
      sa[97] = 0.049323097f;
      sa[98] = 0.2815247f;
      sa[99] = -0.060581245f;
      sa[100] = -0.12653148f;
      sa[101] = -0.055227507f;
      sa[102] = 0.093723044f;
      sa[103] = -0.028624315f;
      sa[104] = -0.7451272f;
      sa[105] = -0.12615448f;
      sa[106] = 0.17820491f;
      sa[107] = 0.012126062f;
      sa[108] = -1.804796E-4f;
      sa[109] = 0.105542794f;
      sa[110] = 0.041763593f;
      sa[111] = 0.027335817f;
      sa[112] = 0.11087468f;
      sa[113] = 0.09026043f;
      sa[114] = 0.034140006f;
      sa[115] = 0.1291591f;
      sa[116] = -0.09454279f;
      sa[117] = 0.032017443f;
      sa[118] = 0.1014205f;
      sa[119] = 0.5719047f;
    }
  }
}
// Neuron weights connecting Rectifier and Rectifier layer
class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Weight_2 implements java.io.Serializable {
  public static final float[] VALUES = new float[32];
  static {
    deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Weight_2_0.fill(VALUES);
  }
  static final class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Weight_2_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = 0.62974095f;
      sa[1] = -0.17489111f;
      sa[2] = 0.6213511f;
      sa[3] = 0.49208176f;
      sa[4] = 0.80381554f;
      sa[5] = -0.4054171f;
      sa[6] = 0.88634163f;
      sa[7] = -0.7424498f;
      sa[8] = 0.31894156f;
      sa[9] = 0.04631073f;
      sa[10] = -0.14504184f;
      sa[11] = 0.035193596f;
      sa[12] = -0.41789344f;
      sa[13] = -0.048881177f;
      sa[14] = -0.3204794f;
      sa[15] = 0.0035687354f;
      sa[16] = 2.5443314E-6f;
      sa[17] = -3.870075E-5f;
      sa[18] = -0.0065520313f;
      sa[19] = -4.6528792E-5f;
      sa[20] = 1.0397356E-5f;
      sa[21] = -1.2266097E-5f;
      sa[22] = -1.2234279E-5f;
      sa[23] = -1.1787422E-5f;
      sa[24] = -0.3268067f;
      sa[25] = 0.3475241f;
      sa[26] = -9.2711113E-4f;
      sa[27] = -0.5022089f;
      sa[28] = -0.27048922f;
      sa[29] = 0.48888704f;
      sa[30] = -0.17796643f;
      sa[31] = 0.5003035f;
    }
  }
}
// Neuron weights connecting Rectifier and Linear layer
class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Weight_3 implements java.io.Serializable {
  public static final float[] VALUES = new float[4];
  static {
    deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Weight_3_0.fill(VALUES);
  }
  static final class deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_Weight_3_0 implements java.io.Serializable {
    static final void fill(float[] sa) {
      sa[0] = 1.3508492f;
      sa[1] = -0.36068138f;
      sa[2] = 2.0630789E-5f;
      sa[3] = -0.7953372f;
    }
  }
}
// The class representing training column names
class NamesHolder_deeplearning_1bfa7a81_7686_4690_a685_d441d7382510 implements java.io.Serializable {
  public static final String[] VALUES = new String[15];
  static {
    NamesHolder_deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_0.fill(VALUES);
  }
  static final class NamesHolder_deeplearning_1bfa7a81_7686_4690_a685_d441d7382510_0 implements java.io.Serializable {
    static final void fill(String[] sa) {
      sa[0] = "SiO2";
      sa[1] = "TiO2";
      sa[2] = "Al2O3";
      sa[3] = "FeOt";
      sa[4] = "MnO";
      sa[5] = "BaO";
      sa[6] = "SrO";
      sa[7] = "MgO";
      sa[8] = "CaO";
      sa[9] = "Li2O";
      sa[10] = "Na2O";
      sa[11] = "K2O";
      sa[12] = "P2O5";
      sa[13] = "H2O";
      sa[14] = "T (K)";
    }
  }
}

